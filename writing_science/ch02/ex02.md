# Step 1. Identify the Key Story Points for your Work.

1. **Opening.** Weapons testing and military training activities leave behind
   explosive munitions, called unexploded ordnance (UXO), which could endanger
   future users of the testing/training sites. There are many such sites across
   the United States with efforts underway to find and remove UXO. My research
   addresses shortcomings in the statistical methods used to map these sites
   and find where UXO items are likely to be located.
2. **Research Question.** Which combination(s) of spatial point process model,
   adaptive sampling scheme, and fitting method yield an acceptable balance
   between accuracy/precision of the posterior intensity function, cost of
   implementation and remediation, and computing time?
3. **Key Results.** (Conjectured because I donâ€™t have results yet):
    - LGCP fit by INLA produces accurate maps with low computational burden.
    - DP mixture of Gaussian components cannot be computed practically.
    - Space-filling survey plans minimize prediction error for a given distance
      traveled.
4. **Main Conclusion.** Batch adaptive sampling using irregular space-filling
   paths combined with an LGCP model fit by INLA can be run online during data
   collection and produces the most accurate and precise posterior intensity
   function of the methods considered here.


# Step 2. Write the Article (800-850 words).

(single UXO application to keep it short for the exercise)

## Characters

- site/background noise
- observed subregion/design
- munitions items
- models/intensity function
- computing methods
- time/money/effort costs

## Conflicts

- background noise vs munitions items
- computing and costs vs models

## Text

### Introduction (introduce characters and conflicts)

Weapons testing and military training activities leave behind explosive
munitions, called unexploded ordnance (UXO), which could endanger future
users of the testing/training sites. There are many such sites across the
United States with efforts underway to find and remove UXO. This research
addresses shortcomings in the statistical methods used to map these sites and
find where UXO items are likely to be located.

Site X (a hypothetical simulated site) was used by the Army for training tank
crews in the early 1940s. The troops fired 76mm high explosive shells at
targets set up around the site, but the records showing the number and
locations of the targets have been lost. The total number of shells fired is
unknown but believed to be in the thousands; there could be dozens of
unexploded shells remaining at the site which need to be found and removed. The
most common strategy is to use metal detectors to search for any munitions
items, including intact shells and fragments of detonated shells, and identify
regions affected by munitions use. Unfortunately, the site also contains
background noise in the form of tens of thousands of small metallic objects
originating from other human activities or the site geology. These cannot be
definitively differentiated from munitions items without the cost-prohibitive
effort of digging up each item, so statistical modeling is used to assist in
discriminating munitions items from background noise. The desired outcome of
this procedure is a map showing the intensity (metallic items per acre) of
metallic items. Any intensity higher than the background level is assumed to
result from munitions use, so regions with high intensity will be thoroughly
searched for unexploded ordnance.

Due to limited time and budget, only 2% of the area of Site X can be surveyed
with metal detectors. Therefore, prior to data collection, the project planners
need to select an optimal path for the survey team to traverse so that the map
of the intensity will be as accurate and precise as possible.

### Methods (describe how the characters address the conflicts)

### Results (climax)

### Conclusion



# Newer freewrite.

## Introduction

Spatial point processes models have long been considered generally infeasible
because of their computational demands, but recent advances in Bayesian
computing have made the Log-Gaussian Cox process an attainable model in
practice [@rueetal, @lindgrenetal, @illianetal, @simpsonetal]. Variable
sampling effort leads to a degraded point pattern [@chakrbortyetal] and it is
relatively simple to accomodate variable sampling effort in these models using
modern computing tools [@yuanetal]. However, the literature on optimal sampling
for spatial point process models in in its infancy [@liuvanhatalo].

Point pattern data are routinely collected in species distribution studies and
ordnance response projects. These applications may use quadrat sampling or
line-transect sampling, with transect sampling being more common in both. When
the objective is mapping where things occur in space, various spatial mapping
procedures have been used. Traditionally these have involved aggregating the
data to grid cell counts or computing moving averages. These have the downside
of introducing arbitrary structure into the data by the choice of gridding
scheme or averaging window, and require uneccessary computation effort
[@simpsonetal]. Software is now available to fit spatial point processes models
to data acquired via diastance sampling and simultaneously estimate the
detection function [@dspat].

In ecological settings, sampling plans are often designed around the goal of
estimating total abundance. Ordnance respones surveys are typically designed
with the objective of detecting (but not necessarily mapping) intensity
hotspots. However, to our knowledge, there has been very little work done in
deciding _where_ to collect data when the goal is to map the intensity using a
patial point process model.

## Sampling Situations

### Transects

- UXO: mapping a site for delineating high-intensity regions
    - minimize time/distance
    - minimize one of these:
        - maximum variance in intensity surface
        - maximum variance in intensity surface _at contours near action level_
        - integrated variance of intensity surface
        - error rates in thresholding (integral of a spatial decision function)
    - minimize variance of coefficients for covariates
- Ecology: mapping plants or animal nests using distance sampling
    - minimize distance
    - minimize variance in parameters of detection function and/or point process
    - minimize one of these:
        - maximum variance in intensity surface
        - integrated variance of intensity surface
    - minimize variance of coefficients for covariates

### Quadrats

- UXO: whatever the UXO literature says quadrats are useful for
- Ecology: mapping plants or animal nests where the goal is probably abundance
  estimation
    - minimize number of quadrats for given area to be covered
    - minimize variance in point process parameters
    - minimize one of these:
        - maximum variance in intensity surface
        - integrated variance of intensity surface
    - minimize variance of coefficients for covariates

### Adaptation Schemes

- Add survey units until reaching uncertainty of cost threshold

### Log-Gaussian Cox Process Model

- Natural log of the intensity function is a realization of a Gaussian process
- Conditional on the intensity, the observable point pattern is a realization
  of a Poisson process
- Thinned point pattern is observed
- Thinned process has intensity equal to original intensity times sampling
  effort or detection function

#### Incorporating False Negatives

- For distance sampling, if the detection function is unknown it can be modeled
  as a log-linear function of the distance to the nearest transect
    - A typical assumption (reasonable in many species distribution surveys) is
      that points on the transects are detected with probability 1
    - This assumption makes the intensity function and detection function
      separately estimible
- For UXO, survey some quadrats/transects twice and give them double the
  sampling effort
    - Metal detectors assumed to detect items with a fixed probability
      (constant dection function)
    - The log dection probability and intercept are linearly dependant and thus
      not separately identifiable when the region is surveyed only once
    - Revisiting should make these identifying (but how, mathematically?)
    - False detects are background noise - not a problem?


# Step 3. Analyze your writing (writing group).
